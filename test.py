#import dataset related packages
from histomics_detect.io import roi_tensors
from histomics_detect.io import read_roi
from histomics_detect.augmentation import crop
from histomics_detect.augmentation import flip
# from histomics_detect.augmentation.augmentation import jitter_boxes
from histomics_detect.boxes.transforms import filter_edge_boxes
import numpy as np
import os
from PIL import Image
from histomics_detect.visualization.visualization import _plot_boxes
from histomics_detect.models.lnms_loss import xor_loss
import tensorflow as tf
import matplotlib.pyplot as plt

from histomics_detect.models.compression_network import CompressionNetwork
from histomics_detect.networks.lnms_cnn import LNMSCNN
from histomics_detect.networks.neighborhood_free_lnms import neighborhood_free_data_formatting


tf.config.run_functions_eagerly(True)

#input data path
path = '../DCC/'

#training parameters
train_tile = 224 #input image size
min_area_thresh = 0.5 # % of object area that must be in crop to be included

#build (.png, image size, slide, .csv) file tuples
files = os.listdir(path)
pngs = [path + f for f in files if f.split('.')[-1] == 'png']
path_len = len(path)
files = [(png, Image.open(png).size, png[path_len:].split('.')[2],
          '.'.join(png.split('.')[0:-1]) + '.csv') for png in pngs]

#filter on png size
files = [(png, size, slide, csv) for (png, size, slide, csv) in files
         if (size[0] > train_tile) and (size[1] > train_tile)]

#randomly assign 20% of slides to validation
slides = list(set([file[2] for file in files]))
id = np.random.randint(0, len(slides)-1, size=(np.ceil(0.2*len(slides)).astype(np.int32)))
validation = [slide for (i, slide) in enumerate(slides) if i in id]
training = list(set(slides).difference(validation))
training_files = [(png, csv) for (png, size, slide, csv) in files if slide in training]
validation_files = [(png, csv) for (png, size, slide, csv) in files if slide in validation]

#convert to tensors
training_rois = roi_tensors(training_files)
validation_rois = roi_tensors(validation_files)

#arguments
width = tf.constant(train_tile, tf.int32)
height = tf.constant(train_tile, tf.int32)
min_area = tf.constant(min_area_thresh, tf.float32)

#build training dataset
# ds_train_roi = tf.data.Dataset.from_tensor_slices(training_rois)
# ds_train_roi = ds_train_roi.map(lambda x: read_roi(x))
# ds_train_roi = ds_train_roi.map(lambda x, y, z: (*crop(x, y, width, height,
#                                                             min_area_thresh), z))
# # ds_train_roi = ds_train_roi.map(lambda x, y: flip(x, y))
# # ds_train_roi = ds_train_roi.map(lambda x, y: (x, jitter_boxes(y, 0.5, 'yx'), y))
#
# ds_train_roi = ds_train_roi.prefetch(tf.data.experimental.AUTOTUNE)
#
# #build validation datasets
# ds_validation_roi = tf.data.Dataset.from_tensor_slices(validation_rois)
# ds_validation_roi = ds_validation_roi.map(lambda x: read_roi(x))
# ds_validation_roi = ds_validation_roi.prefetch(tf.data.experimental.AUTOTUNE)
from histomics_detect.io import dataset
from histomics_detect.augmentation import crop, flip, jitter, shrink

def parser(file):
    name = os.path.splitext(file)[0]
    case = name.split('.')[2]
    roi = '.'.join([name.split('.')[1]] + name.split('.')[-3:])
    return case, roi

ds_train_roi = dataset(path, parser, parser, train_tile, training)
ds_validation_roi = dataset(path, parser, parser, 0, validation)

#build training dataset
ds_train_roi = ds_train_roi.map(lambda x, y, z: (*crop(x, y, width, height,
                                                                 min_area_thresh), z))
ds_train_roi = ds_train_roi.map(lambda x, y, z: (*flip(x, y), z))
ds_train_roi = ds_train_roi.map(lambda x, y, z: (x, jitter(y, 0.05), z))
ds_train_roi = ds_train_roi.map(lambda x, y, z: (x, shrink(y, 0.05), z))
ds_train_roi = ds_train_roi.prefetch(tf.data.experimental.AUTOTUNE)

#build validation datasets
ds_validation_roi = ds_validation_roi.prefetch(tf.data.experimental.AUTOTUNE)
loss_object = tf.keras.losses.MeanSquaredError()
standard = [None, tf.keras.metrics.Mean(name="pos"), tf.keras.metrics.Mean(name="neg")]


#import network generation and training packages
from histomics_detect.networks.rpns import rpn
from histomics_detect.models.faster_rcnn import FasterRCNN
# from histomics_detect.models.faster_rcnn import CustomCallback
from histomics_detect.anchors.create import create_anchors
from histomics_detect.networks.field_size import field_size
# from histomics_detect.boxes.match import calculate_cluster_assignment

#choices for anchor sizes - all anchors 1:1 aspect ratio
# anchor_px = tf.constant([32, 64, 96], dtype=tf.int32) #width/height of square anchors in pixels at input mag.
anchor_px = tf.constant([64], dtype=tf.int32)
#feature network parameters
backbone_stride = 1 #strides in feature generation network convolution
backbone_blocks = 14
backbone_dimension = 256 #number of features generated by rpn convolution

#rpn network parameters
rpn_kernel = [3] #kernel size for rpn convolution
rpn_act_conv = ['relu'] #activation for rpn convolutional layers

#anchor filtering parameters
neg_max = 128 #maximum number of negative/positive anchors to keep in each roi
pos_max = 128
rpn_lmbda = 10.0 #weighting for rpn regression loss
roialign_tiles = 3.0 #roialign - number of horizontal/vertical tiles in a proposal
roialing_pool = 2.0 #roialign - number of horizontal/vertical samples in each tile

#create backbone and rpn networks
resnet50 = tf.keras.applications.ResNet50(
    include_top=False, weights='imagenet', input_tensor=None,
    input_shape=(train_tile, train_tile, 3), pooling=None)
rpnetwork, backbone = rpn(resnet50, n_anchors=tf.size(anchor_px),
                          stride=backbone_stride, blocks=backbone_blocks,
                          kernels=rpn_kernel, dimensions=[backbone_dimension],
                          activations=rpn_act_conv)

from histomics_detect.roialign.roialign import roialign
from histomics_detect.models.lnms_model import LearningNMS
# from histomics_detect.networks.
import yaml
from histomics_detect.boxes.match import cluster_assignment
from histomics_detect.models.lnms_loss import clustering_loss, calculate_labels, normal_clustering_loss
from histomics_detect.models.model_utils import extract_data
from histomics_detect.metrics import iou
from histomics_detect.anchors.create import first_last_anchor_indexes
from histomics_detect.boxes.cross_boxes import cross_from_boxes
from histomics_detect.visualization.lnms_visualization import plot_multiple_outputs

with open('../configs.yml') as config_file:
  configs = yaml.load(config_file)

for key, value in configs['special_configs'].items():
    try:
      configs[key] = eval(value.replace('\\\'', '\''))
    except:
      pass

faster_model = FasterRCNN(rpnetwork, backbone, [width, height], anchor_px, rpn_lmbda)
configs['path'] = '../DCC/'
configs['image_names'] = [] #['93098', '131449'] #  '135062', '135065', '91315',
configs['anchor_px'] = anchor_px

configs['loss_type'] = 'xor'
configs['loss_offset'] = tf.constant(10.0, dtype=tf.float32)
configs['positive_loss_multiplier'] = 30.0
configs["weighted_loss"] = False
configs['variance'] = [6, 6, 4, 4]
configs['samples'] = 2
configs['num_blocks'] = 12
configs['feature_size'] = 128
configs['anchor_size'] = 2048
configs['train_tile'] = 224
configs['threshold'] = 0
configs['initial_prediction_threshold'] = -1
configs['compressed_gradient'] = False
configs['neg_pos_loss'] = False

configs['positive_weight'] = 1 #2.5
configs['compressed_tile_size'] = 14
configs['use_image_features'] = True
configs['final_activation'] = 'sigmoid'
configs['min_cluster_threshold'] = 0
configs['loss_object'] = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE) # tf.keras.losses.BinaryCrossentropy(from_logits=False)#

configs['distributed_training'] = False
configs['norm_loss_weight'] = 0.2
configs['add_regression_param'] = 1  # 0-> no reg, 1-> center regression, 2-> full box regression
configs['use_pos_neg_loss'] = False

# TODO neww
configs['cross_boxes'] = True
configs['cross_scale'] = 3
configs['width'] = width
configs['height'] = height
configs['combine_box_and_cross'] = False
configs['data_only'] = True

compression_model = CompressionNetwork(configs['feature_size'], configs['anchor_size'], backbone)
model = LearningNMS(configs, rpnetwork, backbone, compression_model.compression_layers, [width, height])
#
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))


# model = CompressionNetwork(configs['feature_size'], configs['anchor_size'], backbone)
#
# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
#               loss=tf.keras.losses.MeanSquaredError())
#
model.fit(x=ds_train_roi, batch_size=1, epochs=1, verbose=1, steps_per_epoch=1)

model.save_weights("../testmodel")

# history_callback = model.fit(x=ds_train_roi,batch_size=1, epochs=1, verbose=1, callbacks=[CustomCallback()],
#                              steps_per_epoch=3)

# model2 = LNMSCNN(configs['anchor_size'], configs['feature_size'], 2)

# for (img, boxes, name) in ds_train_roi:
#     norm, boxes, sample_weight = extract_data((img, boxes, name))
#
#     features, rpn_boxes, scores = model.extract_boxes_n_scores(norm)
#     rpn_boxes = rpn_boxes[:1]
#
#     num_anchors = 10
#
#     # features = features[:, 2: -2, 2: -2, :]
#     # rpn_boxes = tf.reshape(rpn_boxes, (1, num_anchors, num_anchors, -1))
#     # scores = tf.reshape(scores, (1, num_anchors, num_anchors, -1))
#     #
#     # new_features = tf.concat((features, rpn_boxes, scores), axis=3)
#
#     ious, _ = iou(rpn_boxes, boxes)
#
#
#     def assign_single_prediction(i) -> tf.int32:
#         assignment = tf.cast(tf.argmax(ious[i]), tf.int32)
#         assignment = tf.cond(ious[i, assignment] > 0, lambda: assignment,
#                              lambda: tf.constant(-1, dtype=tf.int32))
#         return assignment
#
#
#     clusters = tf.vectorized_map(assign_single_prediction, tf.range(0, tf.shape(rpn_boxes)[0]))
#     # return tf.cast(clusters, tf.int32)
#
#     break
#
# field = model.field
# size = tf.reduce_min(model.anchor_px)
#
# first_w, last_w = first_last_anchor_indexes(size, field, width)
# first_w, last_w = tf.cast(first_w, tf.int32), tf.cast(last_w, tf.int32)
# first_h, last_h = first_last_anchor_indexes(size, field, height)
# first_h, last_h = tf.cast(first_h, tf.int32), tf.cast(last_h, tf.int32)
#
# def func(img, boxes, name):
#     norm, boxes, sample_weight = extract_data((img, boxes, name))
#
#     features, rpn_boxes, scores = model.extract_boxes_n_scores(norm)
#
#     labels, indexes = calculate_labels(boxes, rpn_boxes, tf.shape(scores))
#
#     anchors_w = last_w - first_w + 1
#     anchors_h = last_h - first_h + 1
#
#     # todo change last for x and y
#     features = features[:, first_w: last_w+1, first_h: last_h+1, :]
#     rpn_boxes = tf.reshape(rpn_boxes, (1, anchors_w, anchors_h, -1))
#     scores = tf.reshape(scores, (1, anchors_w, anchors_h, -1))
#
#     new_features = tf.concat((features, rpn_boxes, scores), axis=3)
#     labels = tf.reshape(labels, (1, anchors_w, anchors_h, -1))
#
#     return new_features, labels

# for data in ds_train_roi:
#     func(*data)

# ds_train_roi = ds_train_roi.map(func)

# model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=tf.keras.losses.MeanSquaredError())
# model2.fit(ds_train_roi, batch_size=1, epochs=3, verbose=1)


for img, boxes, name in ds_train_roi:
# plot_multiple_outputs(configs: dict, validation_data: tf.data.Dataset, ds_train_roi: tf.data.Dataset,
#                           model_paths: List[str], variable: str, model_variations: List, index: int,
#                           faster_model: tf.keras.Model, callbacks: List[tf.keras.callbacks.Callback]) -> None:
    plot_multiple_outputs(configs, ds_validation_roi, ds_train_roi, ["../testmodel", "../testmodel"], 'bla', [1, 1], 0,
                          faster_model=faster_model, callbacks=[])
    break
#
    # out = model.train_step((img, boxes, name))
    # boxes = boxes.to_tensor()
    # normalize image
    # norm = tf.keras.applications.resnet.preprocess_input(tf.cast(img, tf.float32))
    #
    # # expand dimensions
    # norm = tf.expand_dims(norm, axis=0)
    # model.anchors = create_anchors(anchor_px, model.field, width, height)

    norm, boxes, sample_weight = extract_data((img, boxes, name))
    features, rpn_boxes, scores = model.extract_boxes_n_scores(norm)

    labels, indexes = calculate_labels(boxes, rpn_boxes, tf.shape(scores))

    # features, labels = neighborhood_free_data_formatting((img, boxes, name), model)
    #
    # features, rpn_boxes, scores = model.extract_boxes_n_scores(norm)
    #
    # compressed_features = model.compression_net(features, training=False)
    #
    # cross = cross_from_boxes(boxes, 1, grow=True)
    # cross = tf.reshape(cross, (-1, 4))
    #
    # fig = plt.figure()
    #
    plt.imshow(img)
    _plot_boxes(boxes, 'orange')

    filtered_boxes = tf.gather(rpn_boxes, tf.where(labels == 1))
    _plot_boxes(rpn_boxes, 'r')

    plt.show()
    #
    # fig.savefig("cross_boxes.png")
    break



    # features = backbone(norm, training=False)
    #
    # num_anchors = 10
    #
    # features, rpn_boxes, scores = model.extract_boxes_n_scores(norm)
    #
    # # features = features[:, 2: -2, 2: -2, :]
    # # rpn_boxes = tf.reshape(rpn_boxes, (1, num_anchors, num_anchors, -1))
    # # scores = tf.reshape(scores, (1, num_anchors, num_anchors, -1))
    # compressed_features = model.compression_net(features, training=False)
#
#     # plt.imshow(img)
#     # _plot_boxes(rpn_boxes[0, 0, :, :], 'r')
#     # plt.show()
#
#     # for this to work we need to reshape boxes and scores and not filter anchors in create anchors
#     # new_features = tf.concat((features, rpn_boxes, scores), axis=3)
#
#     output = model2(new_features)
#     print(tf.shape(new_features))
#     print(tf.shape(output))
#
    # calculate interpolated features
    interpolated = model._interpolate_features(compressed_features, rpn_boxes)
    interpolated = tf.concat([scores, interpolated], axis=1)
    #
    nms_output = model.net((interpolated, rpn_boxes), training=True)
    #
    clusters = cluster_assignment(boxes, rpn_boxes, model.min_cluster_threshold)
    loss, labels = clustering_loss(nms_output, clusters, model.loss_object, model.positive_weight,
                                   model.standard, boxes, model.weighted_loss, model.neg_pos_loss)
    # loss, labels = normal_clustering_loss(nms_output, boxes, rpn_boxes, clusters, model.loss_object,
    #                                               model.positive_weight, model.standard, model.weighted_loss,
    #                                               model.neg_pos_loss, model.use_pos_neg_loss, model.norm_loss_weight,
    #                                               model.add_regression_param)
    break
#     #
#     # output_ = model(features)
#     # output = model.net(features)
#     # print(tf.shape(features))
#     # print(tf.shape(output_))
#     break
#     # boxes = boxes.to_tensor()
#     # output_ = model.call((img, boxes, name))
#
#     # calculate_cluster_assignment(boxes, tf.tile(boxes, [2, 1]))
#     # xor_loss(tf.ones((10, 1)), tf.ones((10, 1)))
# #     samples = 2
# #     variance = [6, 6, 4, 4]
# #
# #     rpn_boxes_positive = tf.tile(boxes, [samples, 1]) + tf.stack(
# #         [tf.random.normal([tf.shape(boxes)[0] * samples], stddev=x) for x in variance], axis=1)
# #     rpn_boxes_positive = tf.concat([boxes + tf.random.normal(tf.shape(boxes), stddev=1), rpn_boxes_positive], axis=0)
# #
# #     rpn_boxes = tf.stack([rpn_boxes_positive[:, 0], rpn_boxes_positive[:, 1],  tf.math.abs(rpn_boxes_positive[:,2])+1, tf.math.abs(rpn_boxes_positive[:,3])+1], axis=1)
# #     scores = tf.ones((tf.shape(rpn_boxes)[0],1))/2
#
#
#     # rgb = tf.keras.applications.resnet.preprocess_input(tf.cast(img, tf.float32))
#     #
#     # # expand dimensions
#     # rgb = tf.expand_dims(rgb, axis=0)
#     #
#     # # predict and capture intermediate features
#     # features = backbone(rgb, training=False)
#     #
#     # custom_features = tf.constant([[[[1, 1], [2, 2]], [[3, 3], [4, 4]]]], dtype=tf.float32)
#     # custom_boxes = create_anchors([4], 4, 8, 8)
#     #
#     # custom_boxes2 = create_anchors([4], 4, 8, 8, 2)
#     #
#     # custom_boxes3 = create_anchors([4], 4, 8, 8, 2)
#
#     # f = roialign(features, boxes, model.field, model.pool, model.tiles)
#
#     # loss, indexes = paper_loss(boxes, boxes, tf.zeros((tf.shape(boxes)[0], 1)), loss_object, 1, standard, neg_pos_loss=True)
#     # print(loss)
#     # break
#
# #
# # #create FasterRCNN keras model
# # model = FasterRCNN(rpnetwork, backbone, [width, height], anchor_px, rpn_lmbda)
# #
# # #compile FasterRCNN model with losses
# # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
# #               loss=[tf.keras.losses.BinaryCrossentropy(from_logits=True),
# #                     tf.keras.losses.Huber()])
# #
# # # tf.config.run_functions_eagerly(False)
# #
# # for data in ds_train_roi:
# #     model.train_step(data)
# #     break
#
# #fit FasterRCNN model
# # model.fit(x=ds_train_roi, batch_size=1, epochs=1, verbose=1, callbacks=[CustomCallback()], steps_per_epoch=3)
#
# # demonstrates nms and display of test sample results
# # from histomics_detect.anchors import create_anchors
# # from histomics_detect.boxes.transforms import unparameterize, clip_boxes, tf_box_transform
# # from histomics_detect.metrics.iou import greedy_iou, iou
# # from histomics_detect.models.faster_rcnn import map_outputs
# # from histomics_detect.roialign.roialign import roialign
# # from histomics_detect.visualization import plot_inference
# #
# # # generate sample from validation dataset
# # output = list(ds_validation_roi.shuffle(100).as_numpy_iterator())[0]
# # rgb = output[0]
# # boxes = output[1]
# #
# # # parameters for nms
# # nms_iou = 0.3
# # map_iou = 0.5
# # delta = 0.1
# #
# # # normalize image
# # norm = tf.keras.applications.resnet.preprocess_input(tf.cast(rgb, tf.float32))
# #
# # # expand dimensions
# # norm = tf.expand_dims(norm, axis=0)
# #
# # # predict and capture intermediate features
# # features = model.backbone(norm, training=True)
# # output = model.rpnetwork(features, training=True)
# #
# # # generate anchors
# # anchors = create_anchors(anchor_px, model.field, tf.shape(rgb)[1], tf.shape(rgb)[0])
# #
# # # transform outputs to 2D arrays with anchors in rows
# # rpn_obj = tf.nn.softmax(map_outputs(output[0], anchors,
# #                                     model.anchor_px, model.field))
# # rpn_reg = map_outputs(output[1], anchors, model.anchor_px, model.field)
# # rpn_boxes = unparameterize(rpn_reg, anchors)
# #
# # # clip regressed boxes to border, transform, and do nonmax supression
# # rpn_boxes = clip_boxes(rpn_boxes, tf.shape(rgb)[1], tf.shape(rgb)[0])
# # selected = tf.image.non_max_suppression(tf_box_transform(rpn_boxes),
# #                                         rpn_obj[:, 1], tf.shape(rpn_obj)[0],
# #                                         iou_threshold=nms_iou)
# # rpn_boxes = tf.gather(rpn_boxes, selected, axis=0)
# # rpn_obj = tf.gather(rpn_obj, selected, axis=0)
# #
# # # select objects predicted by region proposal network
# # positive = tf.greater(rpn_obj[:, 1], 0.5)
# # rpn_boxes_positive = tf.boolean_mask(rpn_boxes, positive, axis=0)
# # rpn_obj_positive = tf.boolean_mask(rpn_obj, positive, axis=0)
# #
# # # generate roialign predictions for rpn positive predictions
# # interpolated = roialign(features, rpn_boxes_positive, model.field, pool=2, tiles=3)
# # align_reg = model.fastrcnn(interpolated)
# # align_boxes = unparameterize(align_reg, rpn_boxes_positive)
# #
# # # boxes = filter_edge_boxes(boxes, width, height)
# # # align_boxes = filter_edge_boxes(align_boxes, width, height)
# # # rpn_boxes_positive = filter_edge_boxes(rpn_boxes_positive, width, height)
# #
# # # rpn accuracy measures via greedy iou mapping
# # rpn_ious, _ = iou(rpn_boxes_positive, boxes)
# # precision, recall, tp, fp, fn, tp_list, fp_list, fn_list = greedy_iou(rpn_ious, map_iou)
# # tf.print('rpn precision: ', precision)
# # tf.print('rpn recall: ', recall)
# # tf.print('rpn tp: ', tp)
# # tf.print('rpn fp: ', fp)
# # tf.print('rpn fn: ', fn)
# #
# # # roialign accuracy measures via greedy iou mapping
# # rpn_ious, _ = iou(align_boxes, boxes)
# # precision, recall, tp, fp, fn, tp_list, fp_list, fn_list = greedy_iou(rpn_ious, map_iou)
# # tf.print('roialign precision: ', precision)
# # tf.print('roialign recall: ', recall)
# # tf.print('roialign tp: ', tp)
# # tf.print('roialign fp: ', fp)
# # tf.print('roialign fn: ', fn)
#
# # plot_inference(rgb, boxes, align_boxes, tp_list[:,0], fp_list, fn_list)
# # plt.show()
#
# # for y, w in ds_train_roi:
# #
# #     w_fil = filter_edge_boxes(w.to_tensor(), width, height, 50)
# #
# #     fig = plt.figure()
# #     plt.imshow(y)
# #     _plot_boxes(w.to_tensor(), 'b')
# #     _plot_boxes(w_fil, 'r')
# #     plt.show()
# #     break
