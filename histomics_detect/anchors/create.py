import tensorflow as tf


def create_anchors(anchor_px, field, width, height):
    """Generates anchors given anchor sizes, receptive field size, and input image size.
    
    Anchors are fixed-size boxes whose centers coincide with the centers of the receptive 
    fields of the region proposal network convolutional layers. Each receptive field
    corresponds to a feature map generated by the network. Each field corresponds to a set
    of anchors at that location with various sizes, with each corresponding to an output
    from the objectness and regression network branches. We represent anchors using the
    anchor centers in pixel units relative to the upper left corner of the input image.
    Anchors are generated in a ragged tensor to support variable input image sizes.
        
    Parameters
    ----------
    anchor_px: tensor (int32)
        K-length 1-d tensor containing the anchor width hyperparameter values in pixel 
        units.
    field: float32
        Edge length of the receptive field in pixels. This defines the area of the 
        image that corresponds to 1 feature map and the anchor gridding.
    width: int32
        Input image width in pixels.
    height: int32
        Input image height in pixels.
        
    Returns
    -------
    anchors: tensor (float32)
        M x 4 tensor anchor positions organized in a dense grid over the image
        space. Each row contains the x,y center location of the anchor in pixel 
        units relative in the image coordinate frame, and the anchor width and 
        height.
    """        

    #initialize ragged tensor
    px = tf.RaggedTensor.from_tensor(tf.expand_dims(anchor_px, 1))

    #generate anchors for different sizes and aspect ratios
    anchors = tf.map_fn(lambda x: 
                        _anchors_at_size(tf.squeeze(x), field, width, height), 
                        px, 
                        fn_output_signature=tf.RaggedTensorSpec(ragged_rank=0, 
                                                                dtype=tf.dtypes.float32))

    #convert to tensor and discard zeros
    anchors = tf.reshape(anchors.to_tensor(),
                         [tf.cast(tf.reduce_max(anchors.row_lengths()), tf.int32)
                          * tf.size(anchors.row_lengths()),
                          tf.shape(anchors[0])[1]])
    anchors = tf.boolean_mask(anchors, tf.not_equal(anchors[:,3], 0), axis=0)  
  
    return anchors


def _anchors_at_size(size, field, width, height):
    """Generates anchors at a single anchor size.
    
    Anchors are fixed-size boxes whose centers coincide with the centers of the receptive 
    fields of the region proposal backbone network. Each receptive field corresponds
    to a feature map generated by the network. This function generates anchors at a single
    size, and is called repeatedly to generate a set of anchors of various sizes for each
    receptive field / feature map.
        
    Parameters
    ----------
    size: int32
        K-length 1-d tensor containing the anchor width hyperparameter values in pixel 
        units.
    field: float32
        Edge length of the receptive field in pixels. This defines the area of the 
        image that corresponds to 1 feature map and the anchor gridding.
    width: int32
        Input image width in pixels.
    height: int32
        Input image height in pixels.
        
    Returns
    -------
    anchors: tensor (float32)
        M x 4 tensor anchor positions organized in a dense grid over the image
        space. Each row contains the x,y center location of the anchor in pixel 
        units relative in the image coordinate frame, and the anchor width and 
        height.
    """

    #get anchor corners
    x_corners = _anchor_corners(size, field, width)
    y_corners = _anchor_corners(size, field, height)

    #replicate for coordinate pairing
    x_pair = tf.tile(tf.expand_dims(x_corners, axis=0), [tf.size(y_corners),1])
    y_pair = tf.tile(tf.expand_dims(y_corners, axis=1), [1,tf.size(x_corners)])

    #reshape into N x 4 array
    anchors = tf.stack((tf.reshape(x_pair, tf.size(x_pair)),
                        tf.reshape(y_pair, tf.size(x_pair)),
                        tf.cast(size, tf.float32)*tf.ones(tf.size(x_pair)),
                        tf.cast(size, tf.float32)*tf.ones(tf.size(x_pair))),
                       axis=1)

    return anchors


def _anchor_corners(size, field, length):
    """Generates a sequence of anchor corner positions along one dimension of an image.
    
    Anchors are required to be entirely with the image domain during training. Called
    twice for each image to generate a horizontal sequence and a vertical sequence.
    These sequences are combined using a cartesian product to generate a dense grid
    of anchors over the entire image.
        
    Parameters
    ----------
    size: int32
        Anchor size.
    field: float32
        Edge length of the receptive field in pixels. This defines the area of the 
        image that corresponds to 1 feature map from the backbone network and the 
        anchor gridding.
    length: int32
        Image edge length in pixels.
        
        
    Returns
    -------
    corners: tensor (float32)
        1D tensor of anchor corner positions in pixels.
    """

    #first and last anchor index
    first = tf.math.ceil(tf.cast(size, tf.float32) / 
                         (2*tf.cast(field, tf.float32)) - 1/2)
    last = tf.math.floor((tf.cast(length, tf.float32)- 
                          tf.cast(size,tf.float32)/2) / 
                         tf.cast(field, tf.float32) - 1/2)

    #anchor corners
    corners = tf.cast(field, tf.float32) * (tf.range(first, last+1) + 1/2) - tf.cast(size, tf.float32)/2
    
    return corners
